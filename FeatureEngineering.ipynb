{
 "metadata": {
  "name": "",
  "signature": "sha256:369301b93d63cd3df3e4235df8e327f66d4dee12136c881daf967e7ad8652e9e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Engineering"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "It's not magic, it's math!\n",
      "\n",
      "But, it's kinda magic too!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature engineering is a crucial, yet commonly neglected technique, in machine learning. Datasets in their original form are rarely in such a way, that when modelled, provide outstanding results. A small amount of feature engineering, can significanly enhance a machine learning model, or in some case, create new insights. \n",
      "\n",
      "In this session, we will focus on three key tools used in feature engineering, and use them to create a machine learning classifier. The goal of this session is to empower you to use these valuable tools and techniques in your day to day activities as machine learning engineers.\n",
      "\n",
      "We will be using:\n",
      "\n",
      "- [Pandas](http://pandas.pydata.org/)\n",
      "- [matplotlib](http://matplotlib.org/)\n",
      "- [scikit-learn](http://scikit-learn.org/stable/)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercise 1 - Load some data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start by loading a dataset which is based on the following webpages:\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<td><img width=200 height=150 src=\"./data/featureengineering/1398282399_thumb.png\"/></td>\n",
      "<td><img width=200 height=150 src=\"./data/featureengineering/1398282433_thumb.png\"/></td>\n",
      "<td><img width=200 height=150 src=\"./data/featureengineering/1398282478_thumb.png\"/></td>\n",
      "<td><img width=200 height=150 src=\"./data/featureengineering/1398282519_thumb.png\"/></td>\n",
      "</tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pages = pickle.load(open('./data/pages.pkl', 'r'))\n",
      "page = pages[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each page has the following fields:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print page.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The elements field contains information about all visible text elements on the page, with some metadata:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print page['elements'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first thing we want to do, is get this data into a human readable format, to assist with analysis. Let's start by using the most commonly used object in Pandas, the DataFrame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd # Aliasing Pandas as pd is common, but not necessarily best practice\n",
      "\n",
      "elements = pd.DataFrame(page['elements'])\n",
      "type(elements)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have a DataFrame, which has some great utility methods for working with data, but to start with, let's just eyeball the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elements.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is already useful, we can start to visualize the shape of the data, in a human readable way. We can observe that we have position and size information, the HTML type, and the text of the element. \n",
      "\n",
      "I already have a question though, what is the first visible **p** text element on the page? For this, we can simply sort the table and filter the results to the data we want:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elements[elements.tag == 'p'].sort(['y']).iloc[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> **Your Turn!** Which is the widest span on the page?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Type your solution here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Solution**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -r 1-1 solutions/FeatureEngineering.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercise 2 - Visualize"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, so next, let's get a feel for the visual shape of the dataset, again, Pandas + IPython provide a powerful environment for visualizing data. First, let's inline matplotlib, so we can see our plots inside the notebook:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then, let's answer the question, how do the elements distribute in terms of quanity on the page?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elements.groupby('tag').count().sort('tag')['tag'].plot(kind='barh')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wow! Let's break this down a bit. \n",
      "\n",
      "First, we take our **elements** DataFrame, and apply the groupby function to it, grouping by the tag column. This simply returns a groupby object, with our rows grouped by the **tag**. Since we're interested in the count, we apply the **count()** method, which returns a new DataFrame. We sort this by tag, which returns a sorted DataFrame. From this, we select the tag values, and plot them as a horizontal bar graph."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another powerful feature of Pandas, is the ability to compute new feature values. For example, given our elements, let's compute the area of the elements:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elements['area'] = elements['h'] * elements['w']\n",
      "elements.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> **Your Turn!** What's the aspect ratio for the elements?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Type your solution here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Solution**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -r 3-4 solutions/FeatureEngineering.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It may seem trivial, but you have now just engineered two new features that did not exist in the original dataset, but did exist in the data model. What do these new features tell us?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> **Your Turn!** Plot these new features so that we can understand the relationship between tags and their areas/aspect ratios"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Type your area solution here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Type your aspect ratio solution here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Solutions**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -r 6-6 solutions/FeatureEngineering.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -r 8-8 solutions/FeatureEngineering.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercise 3 - How to train a classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, why is any of this useful? Because building a solid data model helps you build solid machine learning model.\n",
      "\n",
      "Let's posit for a second, that there is a relationship between the shape of product pages, and non-product pages. And given a page, and the function above (tag count), that we would like to determine if it's a product page or not.\n",
      "\n",
      "Let's see what that might look like.\n",
      "\n",
      "The first step is to take our grouping, and turn it into a dictionary, we can do this again, using the conveniences built into Pandas:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elements.groupby('tag').count().sort('tag')['tag'].to_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With this, we now have a set of features we can use to build a model. To train a classifier however, even a simple one for our example, we do need a little more training data.\n",
      "\n",
      "Let's take all the pages and compute their tag counts:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = []\n",
      "labels = []\n",
      "\n",
      "for page in pages[1:4]:\n",
      "    page_elements = pd.DataFrame(page['elements'])\n",
      "    D.append(page_elements.groupby('tag').count().sort('tag')['tag'].to_dict())\n",
      "    if 'sears' in page['url']:\n",
      "        labels.append('non-product')\n",
      "    else:\n",
      "        labels.append('product')\n",
      "\n",
      "print D\n",
      "print labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also, let's **hold back** our original page, which we know to be a product, to test our classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "holdback = elements.groupby('tag').count().sort('tag')['tag'].to_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We then feed this to a very simple, yet powerful classification model, called a Support Vector Machine.\n",
      "\n",
      "We also leverage the dictionary vectorizer to convert our dictionaries into a vectors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm\n",
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "v = DictVectorizer()\n",
      "X = v.fit_transform(D)\n",
      "\n",
      "clf = svm.SVC(kernel=\"rbf\", gamma=0.1)\n",
      "clf.fit(X, labels)\n",
      "\n",
      "clf.predict(v.transform(holdback))[0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we vectorize our list of dictionaries, we created a matrix that mapped the dictionary keys as feature names and the values as feature values, along the lines of a=137, strong=24, etc. \n",
      "\n",
      "We then provided this information to the classifier, and labelled the samples, as product or non-product.\n",
      "\n",
      "We then used our classifier to provide a label for our unseen vector, and as hoped, it predicted the label correctly.\n",
      "\n",
      "There are some issues with our toy approach above, namely overfitting, but for the purposes of the exercise, our classifier does as required."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> **Your Turn!** What happens if we repeat our experiment using a different feature, say surface area or aspect ratio? *Hint*: You can't pass a **nan** value to the classifier, so you might want to think about using [this](http://pandas.pydata.org/pandas-docs/version/0.13.1/generated/pandas.DataFrame.fillna.html)..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Type your solution here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Solution**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -r 14-34 solutions/FeatureEngineering.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercise 4 - ML as a Feature!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While computing new features using heuristics is the most common method of feature engineering, it's also important to note that there are machine learning methods that lend themselves to feature generation too. \n",
      "\n",
      "Remember we had that document title? Looking at the page, it seems that the document title might help us locate the product title of the page:\n",
      "\n",
      "<img width=400 height=400 src=\"./data/featureengineering/1398282399_thumb.png\"/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's reset our page ref\n",
      "page = pages[0]\n",
      "\n",
      "# What is the title again?\n",
      "print page['title']\n",
      "\n",
      "# And let's reconstruct our DataFrame\n",
      "elements = pd.DataFrame(page['elements'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we can see the document title is a good start towards what the page is about, but we can also see there is an ever so slight difference between what is the actual product title, and the document title. While this may seem trivial, these kinds of anomalies haunt ML engineers, so let's dig in a little more...\n",
      "\n",
      "As we did before, and as we will do with every exploration, we have to get the data into a form that is easily understood by the machine learning algorithms. \n",
      "\n",
      "Let's start by constructing our dataset. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_text = []\n",
      "\n",
      "# Let's start by adding the page title to our text list\n",
      "all_text.append(page['title'])\n",
      "\n",
      "# Now, let's add all the text from the page\n",
      "all_text.extend(elements['text'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why did we just do this? Because we need to have all the text together, before we can compare the doc title with the rest of the page. We need to create a vector space where all our vectors are together, otherwise when we compute the term frequency matrix, we will be missing key intersections. \n",
      "\n",
      "Next, let's vectorize this corpus using a term-frequency, inverse document frequency vectorizer. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "X = TfidfVectorizer().fit_transform(all_text)\n",
      "\n",
      "print len(all_text)\n",
      "\n",
      "X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So let's do a quick sanity check. We have **275** text elements. Check. Our tfidf matrix is **275** rows by **356** columns. Check. Wait, **356** columns?\n",
      "\n",
      "Next, we want to add a new column to our DataFrame, which will show us the similarity between the first element, our document title, and the rest of the text on the page. For this we're going to use a similarity measure that will tell us how similar two texts are. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "\n",
      "print all_text[0:1]\n",
      "print all_text[1:2]\n",
      "print all_text[2:3]\n",
      "print 'Sims'\n",
      "print cosine_similarity(X[0:1], X[1:2]) \n",
      "print cosine_similarity(X[0:1], X[2:3]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> **Question?** What just happened here?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So let's go ahead and compute a distance matrix. The cosine_similarity function will accept two matrices, and compute the distances between them. So let's pass our document title as the first matrix of one row, and the rest of the corpa as the second. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cosine_similarity_matrix = cosine_similarity(X[0:1], X).flatten()\n",
      "cosine_similarity_matrix.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, let's sort the distances. Keep in mind, we're no longer in our Pandas dataframe, we're now in a numpy array, so we have to use a different method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cosine_similarity_matrix = cosine_similarity_matrix.argsort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, now, let's have a look at what we have in the matrix. Let's grab the top 5 texts:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "related_text_indices = cosine_similarity_matrix[:-5:-1]\n",
      "related_text_indices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So these are the index positions in our original all_text list, let's roll them out and see the values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[all_text[i] for i in related_text_indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Very interesting! So the first item is our document title, then the most similar texts follow. As we had hoped, the product title is the most similar. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Finished!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Things to keep in mind:\n",
      "    \n",
      "- Pandas is a powerful tool for engineering features, including methods to convert DataFrames to dictionaries, arrays, etc\n",
      "- scikit-learn makes it very easy to vectorize data structures from Pandas and use them to build ML models\n",
      "- IPython and inline matplotlib is a powerful visualization toolchain"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}